#!/usr/bin/env bash

# ============================================================================
# Unite_classify_ITS.sh - Taxonomic classification of ITS sequences using QIIME2
#
# This script:
#
# This script:
# 1. Classifies OTU sequences against the UNITE database using naive Bayes (sklearn)
# 2. Classifies OTU sequences against the UNITE database using Vsearch
#
# Usage: ./Unite_classify_ITS.sh -i INPUT.fa [options]
# SP@NC - email nucleomics@vib.be
# ============================================================================

# -----------------------------------------------------------------------------
# QIIME2 UNITE expected database files (generated by Unite_build_db.sh)
#
# For 97% clustered set:
#   /data/biodata/qiime2_ITS/unite-classifier-fungi_97pc_2025-02-19.qza
#   /data/biodata/qiime2_ITS/unite-sequences-fungi_97pc_2025-02-19.qza
#   /data/biodata/qiime2_ITS/unite-taxonomy-fungi_97pc_2025-02-19.qza
#   /data/biodata/qiime2_ITS/unite-taxonomy-fungi_97pc_2025-02-19.tsv
#   /data/biodata/qiime2_ITS/unite-trainset-fungi_97pc_2025-02-19.fa.gz
#
# For 99% clustered set:
#   /data/biodata/qiime2_ITS/unite-classifier-fungi_99pc_2025-02-19.qza
#   /data/biodata/qiime2_ITS/unite-sequences-fungi_99pc_2025-02-19.qza
#   /data/biodata/qiime2_ITS/unite-taxonomy-fungi_99pc_2025-02-19.qza
#   /data/biodata/qiime2_ITS/unite-taxonomy-fungi_99pc_2025-02-19.tsv
#   /data/biodata/qiime2_ITS/unite-trainset-fungi_99pc_2025-02-19.fa.gz
# -----------------------------------------------------------------------------

# Script metadata
SCRIPT_VERSION="1.1.0"
SCRIPT_AUTHOR="SP@NC (+AI)"
REVISION_DATE="August 26, 2025"

# Exit on error
set -e

# Function to echo commands before executing them
echo_cmd() {
  echo "# $*"
  "$@"
}

# Default values
INPUT_FASTA=""
UNITE_VERSION="2025-02-19"
TAXON_GROUP="fungi"
CLUSTER_ID="99"
QIIME_ENV="qiime2-amplicon-2025.7"
UNITE_DIR="$BIODATA/qiime2_ITS"
OUTPUT_DIR="$(pwd)"
RESULTS_FOLDER="classification_results"
THREADS="16"  # Default number of threads
BATCH_SIZE="auto"  # Default batch size for classification

# Display usage information
usage() {
  echo "Unite_classify_ITS.sh v${SCRIPT_VERSION} - ${REVISION_DATE}"
  echo "Author: ${SCRIPT_AUTHOR}"
  echo
  echo "Usage: $0 -i INPUT.fa [options]"
  echo
  echo "Required arguments:"
  echo "  -i FILE     Input fasta file with OTU sequences (can be gzipped)"
  echo
  echo "Optional arguments:"
  echo "  -o DIR      Output directory (default: current directory)"
  echo "  -r NAME     Results folder name (default: ${RESULTS_FOLDER})"
  echo "  -v VERSION  UNITE version (default: ${UNITE_VERSION})"
  echo "  -t TAXON    Taxon group (default: ${TAXON_GROUP})"
  echo "  -c ID       Cluster ID (default: ${CLUSTER_ID})"
  echo "  -e ENV      Conda environment name (default: ${QIIME_ENV})"
  echo "  -d DIR      UNITE directory (default: ${UNITE_DIR})"
  echo "  -p NUM      Number of threads to use (default: ${THREADS})"
  echo "  -b SIZE     Batch size for classification (default: ${BATCH_SIZE}, use a number for manual sizing)"
  echo "  -h          Display this help message"
  echo
  exit 1
}

# Parse command-line options
while getopts "i:o:r:v:t:c:e:d:p:b:h" opt; do
  case $opt in
    i) INPUT_FASTA="$OPTARG" ;;
    o) OUTPUT_DIR="$OPTARG" ;;
    r) RESULTS_FOLDER="$OPTARG" ;;
    v) UNITE_VERSION="$OPTARG" ;;
    t) TAXON_GROUP="$OPTARG" ;;
    c) CLUSTER_ID="$OPTARG" ;;
    e) QIIME_ENV="$OPTARG" ;;
    d) UNITE_DIR="$OPTARG" ;;
    p) THREADS="$OPTARG" ;;
    b) BATCH_SIZE="$OPTARG" ;;
    h) usage ;;
    \?) echo "Invalid option: -$OPTARG" >&2; usage ;;
    :) echo "Option -$OPTARG requires an argument." >&2; usage ;;
  esac
done

# Check if input file was provided
if [ -z "$INPUT_FASTA" ]; then
  echo "Error: Input fasta file (-i) is required."
  usage
fi

# Check if input file exists
if [ ! -f "$INPUT_FASTA" ]; then
  echo "Error: Input file '$INPUT_FASTA' does not exist."
  exit 1
fi

base_name=$(basename "$INPUT_FASTA")
input_name_no_ext="${base_name%.*}"

# Function to process a fasta file
process_fasta() {
  local input_file="$1"
  local classifier="$2"
  local results_dir="$3"
  local threads="$4"
  local batch_size="$5"

  local base_name=$(basename "$input_file")
  local input_name_no_ext="${base_name%.*}"

  # Check if input file is gzipped and decompress during copy if needed
  local copied_input=""
  if [[ "$input_file" == *.gz ]]; then
    echo "Detected gzipped input file"
    # Remove .gz extension to get the base name
    local uncompressed_name="${input_name_no_ext}"

    echo "Decompressing input file to results directory..."
    echo "# gunzip -c ${input_file} > ${results_dir}/${uncompressed_name}"
    gunzip -c "$input_file" > "${results_dir}/${uncompressed_name}"
    copied_input="${results_dir}/${uncompressed_name}"

    echo "Created uncompressed version: ${copied_input}"
  else
    # Copy the input file to the results directory for portability
    echo "Copying input file to results directory..."
    echo "# cp ${input_file} ${results_dir}/"
    cp "$input_file" "${results_dir}/"
    copied_input="${results_dir}/${base_name}"
  fi


  # Import sequences only if output not present
  if [[ ! -f "${results_dir}/sequences.qza" ]]; then
    echo "Importing sequences from input file..."
    echo "# qiime tools import --type 'FeatureData[Sequence]' --input-path ${copied_input} --output-path ${results_dir}/sequences.qza"
    qiime tools import \
      --type 'FeatureData[Sequence]' \
      --input-path "${copied_input}" \
      --output-path "${results_dir}/sequences.qza"
  else
    echo "Sequences QZA already exists: ${results_dir}/sequences.qza"
    echo "Skipping import."
  fi

  ##################################
  # Classify sequences with sklearn only if output not present
  if [[ ! -f "${results_dir}/sklearn_taxonomy.qza" ]]; then
    echo "Classifying sequences against UNITE database (using ${threads} threads)..."
    echo "# qiime feature-classifier classify-sklearn --i-classifier ${classifier} --i-reads ${results_dir}/sequences.qza --o-classification ${results_dir}/sklearn_taxonomy.qza --p-n-jobs ${threads} --p-reads-per-batch ${batch_size} --p-pre-dispatch '2*n_jobs'"
    qiime feature-classifier classify-sklearn \
      --i-classifier "${classifier}" \
      --i-reads "${results_dir}/sequences.qza" \
      --o-classification "${results_dir}/sklearn_taxonomy.qza" \
      --p-n-jobs "${threads}" \
      --p-reads-per-batch "${batch_size}" \
      --p-pre-dispatch "2*n_jobs"
  else
    echo "Sklearn taxonomy QZA already exists: ${results_dir}/sklearn_taxonomy.qza"
    echo "Skipping sklearn classification."
  fi

  # Export sklearn taxonomy results only if output not present
  local tmp_export_dir="/tmp/taxonomy-export-$$-${RANDOM}"
  if [[ ! -f "${results_dir}/sklearn_classified_${input_name_no_ext}.tsv" ]]; then
    echo "Exporting taxonomy results..."
    echo "# qiime tools export --input-path ${results_dir}/sklearn_taxonomy.qza --output-path ${tmp_export_dir}"
    qiime tools export \
      --input-path "${results_dir}/sklearn_taxonomy.qza" \
      --output-path "${tmp_export_dir}"

    echo "Moving taxonomy file to results directory..."
    echo "# mv ${tmp_export_dir}/taxonomy.tsv ${results_dir}/sklearn_classified_${input_name_no_ext}.tsv"
    mv "${tmp_export_dir}/taxonomy.tsv" "${results_dir}/sklearn_classified_${input_name_no_ext}.tsv"
  else
    echo "Sklearn classified TSV already exists: ${results_dir}/sklearn_classified_${input_name_no_ext}.tsv"
    echo "Skipping sklearn taxonomy export."
  fi

  # Clean up the temporary directory
  echo "Cleaning up temporary files..."
  echo "# rm -rf ${tmp_export_dir}"
  rm -rf "${tmp_export_dir}"

  echo "Sklearn Classification complete for ${base_name}"
  echo "Results saved as: ${results_dir}/sklearn_classified_${input_name_no_ext}.tsv"


  ##################################
  # Set vsearch reference files to match classifier build using global variables
  local sequences_name="${UNITE_DIR}/unite-sequences-${TAXON_GROUP}_${CLUSTER_ID}pc_${UNITE_VERSION}.qza"
  local taxonomy_name="${UNITE_DIR}/unite-taxonomy-${TAXON_GROUP}_${CLUSTER_ID}pc_${UNITE_VERSION}.qza"

  # Classify sequences using vsearch only if output not present
  if [[ ! -f "${results_dir}/vsearch_taxonomy.qza" || ! -f "${results_dir}/vsearch_search_results.qza" ]]; then
    echo "Classifying sequences against UNITE database using vsearch (threads: ${threads})..."
    echo "# qiime feature-classifier classify-consensus-vsearch --i-query ${results_dir}/sequences.qza --i-reference-reads ${sequences_name} --i-reference-taxonomy ${taxonomy_name} --o-classification ${results_dir}/vsearch_taxonomy.qza --o-search-results ${results_dir}/vsearch_search_results.qza --p-threads ${threads} --p-maxaccepts 10 --p-perc-identity 0.8"
    qiime feature-classifier classify-consensus-vsearch \
      --i-query "${results_dir}/sequences.qza" \
      --i-reference-reads "${sequences_name}" \
      --i-reference-taxonomy "${taxonomy_name}" \
      --o-classification "${results_dir}/vsearch_taxonomy.qza" \
      --o-search-results "${results_dir}/vsearch_search_results.qza" \
      --p-threads "${threads}" \
      --p-maxaccepts 10 \
      --p-perc-identity 0.8
  else
    echo "VSEARCH classification outputs already exist:"
    echo "  ${results_dir}/vsearch_taxonomy.qza"
    echo "  ${results_dir}/vsearch_search_results.qza"
    echo "Skipping vsearch classification."
  fi

  # Export vsearch taxonomy results only if output not present
  local tmp_vsearch_export_dir="/tmp/vsearch-taxonomy-export-$$-${RANDOM}"
  if [[ ! -f "${results_dir}/vsearch_classified_${input_name_no_ext}.tsv" ]]; then
    echo "Exporting vsearch taxonomy results..."
    echo "# qiime tools export --input-path ${results_dir}/vsearch_taxonomy.qza --output-path ${tmp_vsearch_export_dir}"
    qiime tools export \
      --input-path "${results_dir}/vsearch_taxonomy.qza" \
      --output-path "${tmp_vsearch_export_dir}"

    echo "Moving vsearch taxonomy file to results directory..."
    echo "# mv ${tmp_vsearch_export_dir}/taxonomy.tsv ${results_dir}/vsearch_classified_${input_name_no_ext}.tsv"
    mv "${tmp_vsearch_export_dir}/taxonomy.tsv" "${results_dir}/vsearch_classified_${input_name_no_ext}.tsv"
  else
    echo "VSEARCH classified TSV already exists: ${results_dir}/vsearch_classified_${input_name_no_ext}.tsv"
    echo "Skipping vsearch taxonomy export."
  fi

  # Clean up the vsearch temporary directory
  echo "Cleaning up vsearch temporary files..."
  echo "# rm -rf ${tmp_vsearch_export_dir}"
  rm -rf "${tmp_vsearch_export_dir}"

  # Notify user of completion
  echo "VSEARCH classification complete for ${base_name}"
  echo "Results saved as: ${results_dir}/vsearch_classified_${input_name_no_ext}.tsv"

}

# Create output directory if it doesn't exist
echo "# mkdir -p ${OUTPUT_DIR}"
mkdir -p "$OUTPUT_DIR"

# Create results directory
RESULTS_DIR="${OUTPUT_DIR}/${RESULTS_FOLDER}"
echo "# mkdir -p ${RESULTS_DIR}"
mkdir -p "$RESULTS_DIR"
echo "All results will be saved to: ${RESULTS_DIR}"

# Create UNITE directory if it doesn't exist
echo "# mkdir -p ${UNITE_DIR}"
mkdir -p "$UNITE_DIR"

# Check if required conda environment exists
echo "# Checking for conda environment: ${QIIME_ENV}"
if ! conda env list | grep -q "${QIIME_ENV}"; then
  echo "Error: Required conda environment '${QIIME_ENV}' not found!"
  echo "Please create it with: conda create -n ${QIIME_ENV} -c qiime2 qiime2"
  exit 1
fi

# Activate QIIME2 environment
echo "Activating QIIME2 environment..."
echo "# conda activate ${QIIME_ENV}"
eval "$(conda shell.bash hook)"
conda activate "${QIIME_ENV}"

# Get or build the classifier
echo "# Getting classifier..."
CLASSIFIER_PATH="${UNITE_DIR}/unite-classifier-${TAXON_GROUP}_${CLUSTER_ID}pc_${UNITE_VERSION}.qza"

# Save a copy of the classifier information
echo "# Creating classification_info.txt"
echo "QIIME environment: ${QIIME_ENV}" > "${RESULTS_DIR}/classification_info.txt"
echo "Date: $(date)" >> "${RESULTS_DIR}/classification_info.txt"
echo "Classification parameters:" >> "${RESULTS_DIR}/classification_info.txt"
echo "Input file: ${INPUT_FASTA}" >> "${RESULTS_DIR}/classification_info.txt"
echo "UNITE version: ${UNITE_VERSION}" >> "${RESULTS_DIR}/classification_info.txt"
echo "Taxon group: ${TAXON_GROUP}" >> "${RESULTS_DIR}/classification_info.txt"
echo "Cluster ID: ${CLUSTER_ID}" >> "${RESULTS_DIR}/classification_info.txt"
echo "Classifier QZA: ${CLASSIFIER_PATH}" >> "${RESULTS_DIR}/classification_info.txt"
echo "Sequences QZA: ${UNITE_DIR}/unite-sequences-${TAXON_GROUP}_${CLUSTER_ID}pc_${UNITE_VERSION}.qza" >> "${RESULTS_DIR}/classification_info.txt"
echo "Taxonomy QZA: ${UNITE_DIR}/unite-taxonomy-${TAXON_GROUP}_${CLUSTER_ID}pc_${UNITE_VERSION}.qza" >> "${RESULTS_DIR}/classification_info.txt"
echo "Trainset FASTA: ${UNITE_DIR}/unite-trainset-${TAXON_GROUP}_${CLUSTER_ID}pc_${UNITE_VERSION}.fa.gz" >> "${RESULTS_DIR}/classification_info.txt"
echo "Sklearn output: ${RESULTS_DIR}/sklearn_classified_${input_name_no_ext}.tsv" >> "${RESULTS_DIR}/classification_info.txt"
echo "VSEARCH output: ${RESULTS_DIR}/vsearch_classified_${input_name_no_ext}.tsv" >> "${RESULTS_DIR}/classification_info.txt"
echo "Threads: ${THREADS}" >> "${RESULTS_DIR}/classification_info.txt"

# Process the input fasta file with generic output names
echo "# Processing input fasta file..."
process_fasta "$INPUT_FASTA" "$CLASSIFIER_PATH" "$RESULTS_DIR" "$THREADS" "$BATCH_SIZE"

echo "ITS classification completed!"
echo "Results saved to: ${RESULTS_DIR}"
